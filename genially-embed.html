<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Asistente de Innovación Docente</title>
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- 1. Cargar librerías de forma global y compatible -->
    <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@google/genai@1.27.0/dist/index.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

    <style>
        body, html, #root { height: 100vh; margin: 0; padding: 0; overflow: hidden; }
        /* Animación de pulso para el botón de micrófono */
        @keyframes pulse-red {
          0%, 100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
          70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
        }
        .animate-pulse-red {
          animation: pulse-red 2s infinite;
        }
    </style>
</head>
<body class="bg-slate-900 text-white">
    <div id="root"></div>

    <!-- 2. Código de la aplicación React. Babel lo procesará. -->
    <script type="text/babel">
        // --- START: CRITICAL CONFIGURATION ---
        // IMPORTANTE: Reemplaza 'TU_API_KEY_AQUÍ' con tu clave de API real de Google AI Studio.
        // La puedes obtener en: https://aistudio.google.com/app/apikey
        const API_KEY = 'AIzaSyBS2byu06L_fGPs9_VMRg-Q5_SvZ5nOS3w';
        // --- END: CRITICAL CONFIGURATION ---

        // Acceder a las librerías cargadas globalmente
        const { useState, useCallback, useRef, useEffect } = React;
        const { createRoot } = ReactDOM;
        const { GoogleGenAI, Modality } = self.GoogleGenAI;

        // --- INICIO: Contenido de utils/audioUtils.ts ---
        function decode(base64) {
          const binaryString = atob(base64);
          const len = binaryString.length;
          const bytes = new Uint8Array(len);
          for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i);
          }
          return bytes;
        }

        async function decodeAudioData(data, ctx, sampleRate, numChannels) {
          const dataInt16 = new Int16Array(data.buffer);
          const frameCount = dataInt16.length / numChannels;
          const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);

          for (let channel = 0; channel < numChannels; channel++) {
            const channelData = buffer.getChannelData(channel);
            for (let i = 0; i < frameCount; i++) {
              channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
            }
          }
          return buffer;
        }
        // --- FIN: Contenido de utils/audioUtils.ts ---

        // --- INICIO: Contenido de services/geminiService.ts ---
        const SYSTEM_INSTRUCTION = `Eres un asistente virtual experto en el sistema de evaluación. Tu conocimiento abarca tres áreas principales:
1.  **Normativa en Castilla y León:** Dominas el sistema de evaluación de la Educación Secundaria Obligatoria (ESO) en la comunidad autónoma de Castilla y León, España.
2.  **Técnicas e Instrumentos:** Eres un especialista en diversas técnicas, instrumentos y herramientas de evaluación educativa (rúbricas, porfolios, listas de cotejo, etc.).
3.  **Innovación Educativa:** Estás al día de las últimas tendencias en innovación educativa aplicada a la evaluación, como la evaluación formativa, la autoevaluación, la coevaluación y el uso de la tecnología.

Tu propósito es responder de manera clara, precisa y concisa a las preguntas de estudiantes, padres y profesores sobre estos temas. Basa tus respuestas en la normativa vigente y en principios pedagógicos sólidos. No respondas preguntas que no estén relacionadas con la evaluación. Sé amable y profesional en todo momento. Formatea tus respuestas con Markdown para una mejor legibilidad, usando listas, negritas, etc. cuando sea apropiado.`;

        const getChatbotResponse = async (prompt) => {
          if (!API_KEY || API_KEY === 'AIzaSyAYC2dCMbxWkqyWzDro5_HszQ2_H5Y6g4M') {
            return "Error: La clave de API no ha sido configurada. Por favor, contacta al administrador.";
          }

          try {
            const ai = new GoogleGenAI({ apiKey: API_KEY });
            const response = await ai.models.generateContent({
              model: "gemini-2.5-flash",
              contents: prompt,
              config: {
                systemInstruction: SYSTEM_INSTRUCTION,
              },
            });
            
            return response.text;
          } catch (error) {
            console.error("Error calling Gemini API for text:", error);
            return "Lo siento, ha ocurrido un error al conectar con el servicio de IA. Es posible que la clave de API sea inválida o haya expirado.";
          }
        };

        const getTextToSpeechResponse = async (text) => {
          if (!API_KEY || API_KEY === 'AIzaSyAYC2dCMbxWkqyWzDro5_HszQ2_H5Y6g4M') {
            throw new Error("API_KEY not configured");
          }

          try {
            const ai = new GoogleGenAI({ apiKey: API_KEY });
            const response = await ai.models.generateContent({
                model: "gemini-2.5-flash-preview-tts",
                contents: [{ parts: [{ text }] }],
                config: {
                    responseModalities: [Modality.AUDIO],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: 'Kore' },
                        },
                    },
                },
            });

            const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
            if (!base64Audio) {
                throw new Error("No audio data received from API.");
            }
            return base64Audio;
          } catch (error) {
            console.error("Error calling Gemini API for TTS:", error);
            throw new Error("Failed to get audio response from Gemini API.");
          }
        };
        // --- FIN: Contenido de services/geminiService.ts ---

        // --- INICIO: Componentes de Iconos ---
        const UserIcon = () => (
          <div className="w-10 h-10 rounded-full bg-slate-600 flex-shrink-0 flex items-center justify-center border-2 border-slate-400">
            <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6 text-slate-300" viewBox="0 0 24 24" strokeWidth="2" stroke="currentColor" fill="none" strokeLinecap="round" strokeLinejoin="round">
              <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
              <path d="M8 7a4 4 0 1 0 8 0a4 4 0 0 0 -8 0" />
              <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
            </svg>
          </div>
        );

        const BotIcon = () => (
          <div className="w-10 h-10 rounded-full bg-slate-600 flex-shrink-0 flex items-center justify-center border-2 border-cyan-400 shadow-lg">
            <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6 text-cyan-300" viewBox="0 0 24 24" strokeWidth="2" stroke="currentColor" fill="none" strokeLinecap="round" strokeLinejoin="round">
              <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
              <path d="M8 16c.83 .56 1.83 1 3 1s2.17 -.44 3 -1" />
              <path d="M12 2a10 10 0 0 1 7.12 17.12a10 10 0 0 1 -14.24 0a10 10 0 0 1 7.12 -17.12z" />
              <path d="M9.5 10a.5 .5 0 1 1 0 -1a.5 .5 0 0 1 0 1z" />
              <path d="M14.5 10a.5 .5 0 1 1 0 -1a.5 .5 0 0 1 0 1z" />
            </svg>
          </div>
        );

        const SendIcon = () => (
          <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6" viewBox="0 0 24 24" strokeWidth="2" stroke="currentColor" fill="none" strokeLinecap="round" strokeLinejoin="round">
            <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
            <path d="M10 14l11 -11" />
            <path d="M21 3l-6.5 18a.55 .55 0 0 1 -1 0l-3.5 -7l-7 -3.5a.55 .55 0 0 1 0 -1l18 -6.5" />
          </svg>
        );

        const MicrophoneIcon = () => (
            <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6 text-white" viewBox="0 0 24 24" strokeWidth="2" stroke="currentColor" fill="none" strokeLinecap="round" strokeLinejoin="round">
                <path stroke="none" d="M0 0h24v24H0z" fill="none" />
                <path d="M9 2m0 3a3 3 0 0 1 3 -3h0a3 3 0 0 1 3 3v5a3 3 0 0 1 -3 3h0a3 3 0 0 1 -3 -3z" />
                <path d="M5 10a7 7 0 0 0 14 0" />
                <path d="M8 21l8 0" />
                <path d="M12 17l0 4" />
            </svg>
        );

        const SpeakerIcon = () => (
          <svg xmlns="http://www.w3.org/2000/svg" className="h-5 w-5" viewBox="0 0 24 24" strokeWidth="2" stroke="currentColor" fill="none" strokeLinecap="round" strokeLinejoin="round">
            <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
            <path d="M15 8a5 5 0 0 1 0 8" />
            <path d="M17.7 5a9 9 0 0 1 0 14" />
            <path d="M6 15h-2a1 1 0 0 1 -1 -1v-4a1 1 0 0 1 1 -1h2l3.5 -4.5a.8 .8 0 0 1 1.5 .5v14a.8 .8 0 0 1 -1.5 .5l-3.5 -4.5" />
          </svg>
        );
        // --- FIN: Componentes de Iconos ---

        // --- INICIO: Contenido de components/Avatar.tsx ---
        const Avatar = ({ isSpeaking }) => {
          const IDLE_AVATAR_URL = "https://i.gifer.com/ZNeT.gif";
          const TALKING_AVATAR_URL = "https://i.gifer.com/9aJ.gif";

          return (
            <div className="relative w-40 h-40 lg:w-48 lg:h-48 rounded-full overflow-hidden border-4 border-cyan-500 shadow-2xl shadow-cyan-500/20">
              <img
                src={isSpeaking ? TALKING_AVATAR_URL : IDLE_AVATAR_URL}
                alt="Asistente Virtual Animado"
                className="w-full h-full object-cover"
                key={isSpeaking ? 'talking' : 'idle'}
              />
              <div className="absolute inset-0 bg-gradient-to-t from-slate-900/50 to-transparent"></div>
            </div>
          );
        };
        // --- FIN: Contenido de components/Avatar.tsx ---

        // --- INICIO: Contenido de components/ChatWindow.tsx ---
        const ChatWindow = ({ messages, isLoading, onSendMessage, onTextToSpeech }) => {
          const [inputValue, setInputValue] = useState('');
          const [isListening, setIsListening] = useState(false);
          const messagesEndRef = useRef(null);
          const recognitionRef = useRef(null);
          
          const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
          const isSpeechRecognitionSupported = !!SpeechRecognition;

          const scrollToBottom = () => {
            messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
          };

          useEffect(scrollToBottom, [messages, isLoading]);

          useEffect(() => {
            if (!isSpeechRecognitionSupported) return;
            
            const recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.lang = 'es-ES';
            recognition.interimResults = false;

            recognition.onresult = (event) => {
              const transcript = event.results[0][0].transcript;
              setInputValue(transcript);
            };
            recognition.onstart = () => setIsListening(true);
            recognition.onend = () => setIsListening(false);
            recognition.onerror = (event) => {
                console.error("Speech recognition error:", event.error);
                setIsListening(false);
            }
            
            recognitionRef.current = recognition;

            return () => {
              if (recognitionRef.current) {
                recognitionRef.current.stop();
              }
            }
          }, [isSpeechRecognitionSupported]);

          const handleSubmit = (e) => {
            e.preventDefault();
            if (inputValue.trim() && !isLoading) {
              onSendMessage(inputValue);
              setInputValue('');
            }
          };

          const handleMicClick = () => {
            if (isLoading || !recognitionRef.current) return;

            if (isListening) {
              recognitionRef.current.stop();
            } else {
              setInputValue(''); // Clear input before listening
              recognitionRef.current.start();
            }
          };

          return (
            <div className="flex flex-col h-full bg-slate-900">
              <div className="flex-1 overflow-y-auto p-6 space-y-6">
                {messages.map((msg, index) => {
                  if (msg.sender === 'user') {
                    return (
                      <div key={index} className="flex items-start gap-4 justify-end">
                        <div className="max-w-xl p-4 rounded-2xl shadow-md bg-cyan-600 rounded-br-none"
                             dangerouslySetInnerHTML={{ __html: msg.text.replace(/\n/g, '<br />') }}>
                        </div>
                        <UserIcon />
                      </div>
                    );
                  } else { // sender === 'bot'
                    return (
                      <div key={index} className="flex items-start gap-4 justify-start">
                        <BotIcon />
                        <div className="flex items-end gap-2">
                          <div className="max-w-xl p-4 rounded-2xl shadow-md bg-slate-700 rounded-bl-none"
                               dangerouslySetInnerHTML={{ __html: msg.text.replace(/\n/g, '<br />') }}>
                          </div>
                          <button
                            onClick={() => onTextToSpeech(msg.text)}
                            className="p-2 rounded-full text-slate-400 hover:bg-slate-700 hover:text-cyan-400 transition-colors duration-200 focus:outline-none focus:ring-2 focus:ring-cyan-500 mb-1"
                            aria-label="Leer en voz alta"
                          >
                            <SpeakerIcon />
                          </button>
                        </div>
                      </div>
                    );
                  }
                })}
                {isLoading && (
                  <div className="flex items-start gap-4 justify-start">
                    <BotIcon />
                    <div className="max-w-xl p-4 rounded-2xl bg-slate-700 rounded-bl-none">
                      <div className="flex items-center space-x-2">
                        <div className="w-2.5 h-2.5 bg-cyan-400 rounded-full animate-pulse"></div>
                        <div className="w-2.5 h-2.5 bg-cyan-400 rounded-full animate-pulse [animation-delay:0.2s]"></div>
                        <div className="w-2.5 h-2.5 bg-cyan-400 rounded-full animate-pulse [animation-delay:0.4s]"></div>
                      </div>
                    </div>
                  </div>
                )}
                <div ref={messagesEndRef} />
              </div>

              <div className="p-4 bg-slate-800 border-t border-slate-700">
                <form onSubmit={handleSubmit} className="flex items-center gap-4">
                  <input
                    type="text"
                    value={inputValue}
                    onChange={(e) => setInputValue(e.target.value)}
                    placeholder="Escribe tu pregunta o usa el micrófono..."
                    disabled={isLoading}
                    className="flex-1 w-full bg-slate-700 text-gray-200 placeholder-slate-400 rounded-full py-3 px-5 focus:outline-none focus:ring-2 focus:ring-cyan-500 transition duration-300 disabled:opacity-50"
                  />
                  {isSpeechRecognitionSupported && (
                    <button
                        type="button"
                        onClick={handleMicClick}
                        disabled={isLoading}
                        className={`p-3 rounded-full transition duration-300 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-slate-800 disabled:cursor-not-allowed ${isListening ? 'bg-red-500 hover:bg-red-600 focus:ring-red-400 animate-pulse-red' : 'bg-slate-600 hover:bg-slate-500 focus:ring-cyan-400'}`}
                        aria-label={isListening ? 'Detener grabación' : 'Grabar audio'}
                    >
                        <MicrophoneIcon />
                    </button>
                  )}
                  <button
                    type="submit"
                    disabled={isLoading || !inputValue.trim()}
                    className="bg-cyan-600 hover:bg-cyan-500 disabled:bg-slate-600 disabled:cursor-not-allowed text-white rounded-full p-3 transition duration-300 focus:outline-none focus:ring-2 focus:ring-cyan-400 focus:ring-offset-2 focus:ring-offset-slate-800"
                    aria-label="Enviar mensaje"
                  >
                    <SendIcon />
                  </button>
                </form>
              </div>
            </div>
          );
        };
        // --- FIN: Contenido de components/ChatWindow.tsx ---

        // --- INICIO: Contenido de App.tsx ---
        const App = () => {
          const [messages, setMessages] = useState([
            {
              sender: 'bot',
              text: '¡Hola! Soy tu asistente virtual. ¿Qué te gustaría saber sobre la evaluación de secundaria en Castilla y León?',
            },
          ]);
          const [isLoading, setIsLoading] = useState(false);
          const [error, setError] = useState(null);
          const [isSpeaking, setIsSpeaking] = useState(false);

          const audioContextRef = useRef(null);
          const audioQueueRef = useRef([]);
          const isPlayingRef = useRef(false);
          const currentSourceRef = useRef(null);

          const playAudio = useCallback(async () => {
            if (isPlayingRef.current || audioQueueRef.current.length === 0) {
              if(audioQueueRef.current.length === 0) {
                setIsSpeaking(false);
              }
              return;
            }

            isPlayingRef.current = true;
            setIsSpeaking(true);
            const textToPlay = audioQueueRef.current.shift();

            if (!textToPlay) {
              setIsSpeaking(false);
              isPlayingRef.current = false;
              return;
            }

            try {
              const base64Audio = await getTextToSpeechResponse(textToPlay);
              
              if (!audioContextRef.current) {
                audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
              }
              const audioContext = audioContextRef.current;
              
              const decodedData = decode(base64Audio);
              const audioBuffer = await decodeAudioData(decodedData, audioContext, 24000, 1);
              
              const source = audioContext.createBufferSource();
              currentSourceRef.current = source;
              source.buffer = audioBuffer;
              source.connect(audioContext.destination);
              source.onended = () => {
                currentSourceRef.current = null;
                isPlayingRef.current = false;
                playAudio();
              };
              source.start();

            } catch (err) {
              console.error("Error playing audio:", err);
              const errorMessage = 'Error al reproducir el audio.';
              setMessages(prev => [...prev, { sender: 'bot', text: errorMessage }]);
              isPlayingRef.current = false;
              playAudio();
            }
          }, []);
          
          const handleTextToSpeech = useCallback((text) => {
            if (currentSourceRef.current) {
                currentSourceRef.current.onended = null;
                currentSourceRef.current.stop();
                currentSourceRef.current = null;
            }
            audioQueueRef.current = [text];
            isPlayingRef.current = false;
            setIsSpeaking(false);
            playAudio();
          }, [playAudio]);

          const handleSendMessage = useCallback(async (text) => {
            if (!text.trim()) return;

            const userMessage = { sender: 'user', text };
            setMessages((prevMessages) => [...prevMessages, userMessage]);
            setIsLoading(true);
            setError(null);

            try {
              const botResponseText = await getChatbotResponse(text);
              const botMessage = { sender: 'bot', text: botResponseText };
              setMessages((prevMessages) => [...prevMessages, botMessage]);
              audioQueueRef.current.push(botResponseText);
              playAudio();

            } catch (err) {
              const errorMessage = 'Lo siento, ha ocurrido un error. Por favor, inténtalo de nuevo más tarde.';
              setError(errorMessage);
              const botErrorMessage = { sender: 'bot', text: errorMessage };
              setMessages((prevMessages) => [...prevMessages, botErrorMessage]);
            } finally {
              setIsLoading(false);
            }
          }, [playAudio]);

          return (
            <div className="flex flex-col md:flex-row h-screen font-sans bg-slate-900 text-gray-200">
              <div className="md:w-1/3 w-full h-1/3 md:h-full bg-slate-800 flex flex-col items-center justify-center p-6 border-r border-slate-700 shadow-lg">
                <Avatar isSpeaking={isSpeaking} />
                <h1 className="text-2xl lg:text-3xl font-bold mt-4 text-cyan-400 text-center">Asistente de Innovación Docente</h1>
                <p className="text-slate-400 mt-2 text-center text-sm lg:text-base">Impulsado por la Universidad de León</p>
              </div>
              <div className="md:w-2/3 w-full h-2/3 md:h-full flex flex-col">
                <ChatWindow
                  messages={messages}
                  isLoading={isLoading}
                  error={error}
                  onSendMessage={handleSendMessage}
                  onTextToSpeech={handleTextToSpeech}
                />
              </div>
            </div>
          );
        };
        // --- FIN: Contenido de App.tsx ---

        // --- INICIO: Lógica de renderizado de index.tsx ---
        const rootElement = document.getElementById('root');
        const root = createRoot(rootElement);
        root.render(<App />);
        // --- FIN: Lógica de renderizado de index.tsx ---

    </script>
</body>
</html>